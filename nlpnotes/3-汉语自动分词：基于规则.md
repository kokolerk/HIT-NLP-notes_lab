# 3.汉语自动分词

## 词法分析：概念

- word tokenization
- word stemming（词干提取）
- lemmatization（词形还原）
- 中文：词性标注，命名实体识别

## 分词和分词标注

## 中文分词：理性主义and经验主义

- 理性主义（基于词典，规则的）

  - 基于字符串匹配算法：

    - 正向最大匹配，
    - 反向最大匹配

    上述两种方法存在问题：增加知识，局部修改；为了发现分词的歧义，可以改进为双向最大匹配，将两种结果进行对比，从而决定正确的结果

    - ==最短路径分词==
      - 寻找分词结果中含词最少的，可以用动态规划算法
      - 为了降低切分的可能性，引入概率：
        - 分为非统计的粗切分模型和统计粗切分模型
      - 优点是好于FMM,BMM结果，但是缺点是忽略了所有覆盖歧义，也无法解决大部分的交叉歧义。

- 经验主义

  - 最大词频分词法
    - 出现频率越高的词越可靠
    - 技术——动态规划，有向图求最优

## 中文分词：问题与发现

- 分词规范
- 歧义
  - 交集型——AJB：AJ,JB都是词，例如：==美国会==通过法案，==结合成==分子
    - 链长
  - 组合型——AB：A,B都是词，例如：起身
  - 真歧义/伪歧义

真实文本中分词歧义分布：交集型：组合型=1:22

真歧义：伪歧义=6:94

- 未登录词识别
- 分词质量评价
  - precision（除以切分结果总数）
  - recall（除以正确结果总数）
  - F

